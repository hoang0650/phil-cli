import streamlit as st
import sys
import os
sys.path.append("/app")
from src.agent_graph import app_graph
from src.tools_audio import transcribe_audio, speak_text
from src.tools_project import handle_upload, zip_project_for_download

st.set_page_config(page_title="Phil AI Agent 1.0.0", layout="wide")

st.title("ğŸ¤– Phil AI Agent 1.0.0")
st.caption("Nghe - NÃ³i - NhÃ¬n - Code - Tá»± Há»c")

# Sidebar: Inputs
with st.sidebar:
    st.header("Project Workspace")
    
    # 1. Upload File/Zip
    uploaded_file = st.file_uploader("KÃ©o tháº£ Project (.zip) hoáº·c File code", type=["zip", "py", "js", "txt", "md"])
    
    project_tree = ""
    if uploaded_file:
        # LÆ°u file vÃ  láº¥y cáº¥u trÃºc thÆ° má»¥c
        with st.spinner("Äang giáº£i nÃ©n vÃ  phÃ¢n tÃ­ch project..."):
            project_tree = handle_upload(uploaded_file, st.session_state.user_id)
        st.success("ÄÃ£ táº£i lÃªn thÃ nh cÃ´ng!")
        
        # Hiá»ƒn thá»‹ cÃ¢y thÆ° má»¥c
        st.code(project_tree, language="text")

with st.sidebar:
    st.header("GiÃ¡c quan")
    uploaded_img = st.file_uploader("Gá»­i áº£nh (Vision)", type=["jpg", "png"])
    uploaded_audio = st.file_uploader("Gá»­i giá»ng nÃ³i (Voice)", type=["wav", "mp3"])
    
    image_url = ""
    if uploaded_img:
        # Save temp to pass to agent
        with open("workspace/input_img.jpg", "wb") as f: f.write(uploaded_img.getbuffer())
        image_url = "workspace/input_img.jpg" # Local path logic needs refinement for real URL
        st.image(uploaded_img, caption="ÄÃ£ nháº­n áº£nh")

# Chat Interface
if final_input:
    # Truyá»n thÃªm thÃ´ng tin project vÃ o Agent
    inputs = {
        "user_id": st.session_state.user_id,
        "user_input_vn": final_input,
        "project_structure": project_tree, # Truyá»n cÃ¢y thÆ° má»¥c vÃ o nÃ£o AI
        # ...
    }
    
    # Cháº¡y Agent
    with st.spinner("Phil Ä‘ang Ä‘á»c code vÃ  sá»­a lá»—i..."):
        final_state = app_graph.invoke(inputs)
        bot_response = final_state['final_response_vn']

    # --- HIá»‚N THá»Š Káº¾T QUáº¢ ---
    with st.chat_message("assistant"):
        st.write(bot_response)
        
        # 2. Táº¡o nÃºt Download náº¿u AI Ä‘Ã£ sá»­a code
        # (Logic: Náº¿u trong quÃ¡ trÃ¬nh cháº¡y, AI cÃ³ gá»i hÃ m write_to_project -> cho phÃ©p download)
        zip_path = zip_project_for_download(st.session_state.user_id)
        
        with open(zip_path, "rb") as f:
            st.download_button(
                label="ğŸ“¦ Táº£i vá» Project Ä‘Ã£ sá»­a (.zip)",
                data=f,
                file_name="fixed_project.zip",
                mime="application/zip"
            )
            
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])
        if "audio" in msg:
            st.audio(msg["audio"])

# Input Logic
user_text = st.chat_input("Nháº­p yÃªu cáº§u...")
audio_text = ""

if uploaded_audio:
    with open("workspace/input_audio.wav", "wb") as f: f.write(uploaded_audio.getbuffer())
    st.toast("Äang nghe...")
    audio_text = transcribe_audio("workspace/input_audio.wav")
    st.info(f"ÄÃ£ nghe tháº¥y: {audio_text}")

final_input = user_text if user_text else audio_text

if final_input:
    # 1. Hiá»ƒn thá»‹ user msg
    st.session_state.messages.append({"role": "user", "content": final_input})
    with st.chat_message("user"):
        st.write(final_input)

    # 2. Cháº¡y Agent
    with st.spinner("Agent Ä‘ang suy nghÄ© & viáº¿t code..."):
        inputs = {
            "user_input_vn": final_input, 
            "image_url": image_url, 
            "iterations": 0,
            "technical_plan": "", "code": "", "exec_result": ""
        }
        final_state = app_graph.invoke(inputs)
        bot_response = final_state['final_response_vn']

    # 3. Táº¡o giá»ng nÃ³i (TTS)
    audio_path = speak_text(bot_response)

    # 4. Hiá»ƒn thá»‹ Bot msg
    msg_data = {"role": "assistant", "content": bot_response}
    if audio_path:
        msg_data["audio"] = audio_path
    
    st.session_state.messages.append(msg_data)
    with st.chat_message("assistant"):
        st.write(bot_response)
        if audio_path:
            st.audio(audio_path, format="audio/wav", autoplay=True)